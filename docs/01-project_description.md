# ğŸ§ Top Songs Dashboard - Project Description

## ğŸ§  Overview

This project is a learning-focused, end-to-end data engineering and analytics platform that simulates and processes real-time user song play data. The final output is a web dashboard that displays the **Top 10 songs** for each **region**, updated **hourly** and **daily**. The stack involves streaming data pipelines, data lake storage, enrichment processes, and modern dashboard rendering.

The project is designed to be modular, containerized using Docker, and uses `uv` for Python package management.

---

## ğŸ¯ Objectives

- Simulate real-time song play data with metadata using LLM-generated inputs.
- Ingest and stream data via a REST API into Kafka.
- Use Apache Spark to process streaming data and store it in MinIO (S3-compatible).
- Enrich and aggregate data via Airflow-managed pipelines.
- Persist the final top-song statistics into PostgreSQL for querying.
- Serve this data via a frontend dashboard built in ReactJS.

---

## ğŸ”§ Tech Stack

| Layer               | Technology                             |
|--------------------|-----------------------------------------|
| Data Simulation     | Python + OpenAI API                     |
| API Server          | FastAPI                                 |
| Messaging Queue     | Apache Kafka                            |
| Streaming Processor | Apache Spark Structured Streaming       |
| Object Storage      | MinIO (S3-compatible)                   |
| Workflow Orchestration | Apache Airflow                      |
| Serving DB          | PostgreSQL                              |
| Dashboard Frontend  | ReactJS + Chart.js                      |
| Containerization    | Docker + Docker Compose                 |
| Python Package Mgmt | `uv` (for virtualenv + dependency mgmt) |

---

## ğŸ”„ Data Flow (High-Level)

1. **Simulated clients** send song play events with metadata via REST API.
2. **FastAPI server** pushes events to **Kafka**.
3. **Spark** reads events from Kafka, processes them, and writes to **MinIO** in partitioned Parquet files.
4. **Airflow** runs:
   - Enrichment jobs to add metadata
   - Aggregation jobs to calculate top songs
   - Loading jobs to update PostgreSQL
5. **ReactJS Dashboard** queries PostgreSQL and renders top 10 songs per region/hour/day.

---

## ğŸ“¦ Deliverables

- Dockerized microservices for ingestion, processing, and frontend
- Airflow DAGs for data orchestration
- Clean, testable Python code using `uv`
- React-based web dashboard
- Example simulated data and usage instructions
- Deployment-ready `docker-compose.yaml`

---

## ğŸš€ Project Goals

- Gain hands-on experience with distributed systems (Kafka, Spark)
- Explore real-time streaming architectures
- Practice data orchestration and analytics pipelines
- Design a robust and observable system
- Build a professional-grade data product with modularity and maintainability

---

## ğŸ“ Repository Structure (Tentative)

```css
top_songs_dashboard/
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ .python-version             # Python version lock (for pyenv or uv)
â”œâ”€â”€ pyproject.toml              # Dependency and build configuration using uv
â”œâ”€â”€ README.md                   # Project overview and usage
â”œâ”€â”€ docker/                     # Dockerfiles and container build setup
â”œâ”€â”€ docs/                       # Project documentation, plans, and diagrams

â”œâ”€â”€ top_songs/                  # Main application Python package
â”‚
â”‚   â”œâ”€â”€ cli/                    # CLI commands (e.g., Typer/Click-based interfaces)
â”‚
â”‚   â”œâ”€â”€ core/                   # Core shared logic across domains
â”‚   â”‚   â”œâ”€â”€ config/             # App settings, environment loader, global config
â”‚   â”‚   â”œâ”€â”€ models/             # Shared domain models and schemas
â”‚   â”‚   â””â”€â”€ utils/              # Reusable utilities (logging, validation, etc.)
â”‚
â”‚   â”œâ”€â”€ ingestion/              # Ingestion layer for incoming data
â”‚   â”‚   â”œâ”€â”€ api/                # FastAPI service for receiving event data
â”‚   â”‚   â””â”€â”€ simulator/          # Simulated client that generates song play events
â”‚
â”‚   â”œâ”€â”€ orchestration/          # Workflow orchestration logic
â”‚   â”‚   â””â”€â”€ dags/               # Airflow DAGs or other orchestrated pipelines
â”‚
â”‚   â”œâ”€â”€ processing/             # Data processing jobs
â”‚   â”‚   â”œâ”€â”€ enrichment/         # Metadata enhancement, lookups, etc.
â”‚   â”‚   â””â”€â”€ streaming/          # Real-time processing jobs (e.g., Spark, Kafka)
â”‚
â”‚   â”œâ”€â”€ serving/                # Data serving layer
â”‚   â”‚   â”œâ”€â”€ api/                # Optional API layer for exposing processed data
â”‚   â”‚   â””â”€â”€ dashboard/          # React frontend for visualizing top songs
â”‚
â”‚   â””â”€â”€ storage/                # Data persistence and storage layer
â”‚       â”œâ”€â”€ database/           # PostgreSQL-related logic (schemas, access)
â”‚       â””â”€â”€ object_store/       # S3/MinIO integration for data lake storage
```

---

